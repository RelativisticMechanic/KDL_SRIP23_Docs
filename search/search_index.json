{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome Page","text":""},{"location":"#introduction","title":"Introduction","text":"<p>The Karnataka Data Lake is an ongoing project that aims to unify data from various departments of the Karnataka government into a single cluster than can be queryed through various methods and used by researchers and government officials to implement policy decisions.</p> <p>This documentation is for the backend part of the workflow that is currently a set of scripts and utilties that make it easier to ingest, query and analyse data that is stored on the server and was created over the course of two months during the Summer Research Internship at IIIT Bangalore.</p> <p>Regards, Siddharth Gautam</p>"},{"location":"setup-devenv/","title":"Setup: Development Environment","text":""},{"location":"setup-devenv/#install-wsl","title":"Install WSL","text":"<p>Ensure that you are have WSL (Windows Subsystem for Linux) if you are operating on a Windows system. Apache Druid is only available for Linux systems, so unless you have a Linux machine or are dual booting with a Linux OS, WSL will be the best option.</p> <p>To install WSL, please follow the official instructions here: Install WSL2 on Microsoft Windows.</p> <p>Once you have WSL installed, open a Powershell Window and type \"wsl\", you should have a Linux terminal prompt open up.</p>"},{"location":"setup-devenv/#install-apache-druid","title":"Install Apache Druid","text":"<p>You'll need an installation of Druid. Simply head to Apache Druid Website and download the <code>tar.gz</code> file.</p> <p>Note</p> <p>You'll need OpenJDK 8/11 installed on your Linux distribution to run Druid as it uses Java. DO NOT download OpenJDK-17, it will not work as of writing this documentation.</p> <p>For Ubuntu, the command is:</p> <p><code>apt install openjdk-11-jdk openjdk-11-jre</code></p> <p>Finally, ensure that Java is installed with the command: <code>java --version</code>.</p> <p>I get:</p> <p><code>openjdk version \"11.0.19\" 2023-04-18</code></p> <p>Followed by a long list of Java options.</p> <p>Warning</p> <p>It is recommended that you shift the Druid directory i.e. <code>apache-druid-26.0.0</code> to the WSL home directory (<code>~</code> or <code>/home/&lt;your username&gt;</code>, both are equivalent). This is because Druid has some problems when it is executed from Windows directory such as <code>/mnt/c/Users/username/Downloads</code>.</p>"},{"location":"setup-devenv/#install-php-81","title":"Install PHP 8.1","text":"<p>Find the way to download PHP 8.1 for your WSL Linux distribution. For Ubuntu users, it is as simple as:</p> <p><code>apt install php8.1-cli</code></p> <p>Note</p> <p>Verify using: <code>php --version</code></p> <p>For reference, I get:</p> <p><code>PHP 8.1.2-1ubuntu2.11 (cli) (built: Feb 22 2023 22:56:18) (NTS)</code></p>"},{"location":"setup-devenv/#install-python3-and-python-dependencies","title":"Install Python3 and Python Dependencies","text":"<p>The PHP backend uses Python 3 code to automate many tasks, hence it is required. </p> <p>Note</p> <p>For Ubuntu, simply run: <code>apt install python3</code>.</p> <p>Also, install: <code>apt install python-is-python3</code>. This makes it so that the \"python\" command immediately launches python3.</p> <p>Confirm installation using:</p> <p><code>/usr/bin/python3</code></p> <p>If this works, we are good.</p> <p>The following Python packages are required:</p> <ul> <li>pandas</li> <li>openpyxl</li> <li>requests</li> <li>numpy</li> </ul> <p>Note</p> <p>Install with <code>pip install numpy pandas openpyxl requests</code>.</p>"},{"location":"setup-devenv/#test","title":"Test","text":"<p>Open up two Powershell windows, start Druid in one using: <code>./bin/start-druid</code> from the <code>apache-druid-26.0.0</code> directory you downloaded from Druid website.</p> <p>Start the PHP server in one using <code>php -S localhost:3000 -c .</code> from the <code>data-ingestion/</code> directory in the repository.</p> <p>You should now have a server running on localhost:3000. Visit it and see the System, Python and Druid Status. </p> <p>Congratulations, your development environment is set up.</p>"},{"location":"setup-server/","title":"Setup: Server","text":"<p>Note</p> <p>All this has been done on the current CADS server running on <code>http://cads.iiitb.ac.in</code>. If there appears to be an issue, or you have started a new server to run and test the utilities and the Druid cluster follow along.</p>"},{"location":"setup-server/#ssh-into-server","title":"SSH into Server","text":"<p>After securing the credentials, simply open up a Powershell window and SSH into the server through the command: </p> <p><code>&gt; ssh -p &lt;PORT_NUMBER&gt; hostname@ip</code></p> <p>You'll be prompted to enter the password. Enter in and you'll be logged into the server with a prompt like: <code>iiitb@iiitb-vm $</code>. </p> <p>Both the hostname and the IP should be provided, along with the password and port number. Contact IT, if not.</p>"},{"location":"setup-server/#setup-website","title":"Setup Website","text":"<p>As of the writing of this document, the server used by IIITB is Apache2. So, when you get the server credentials, confirm by visiting the IP address that you are getting an output similar to this:</p> <p></p> <p>Okay, so if you have that, it means the Apache2 Server is set up and ready to deploy the utilities.</p> <p>The default directory that Apache2 looks for webpages is the <code>/var/www/html/</code> directory, for our purposes we created the directory <code>/var/www/html/upload</code>. Simply place all the contents of the <code>data-ingestion/*</code> directory here.</p> <p>Warning</p> <p>Please ensure that the <code>datasets/</code> directory and the <code>metadata.json</code> is backed up if you are planning to delete or replace the <code>/var/www/html/uploads/</code> directory.</p> <p>Warning</p> <p>Please also ensure that read &amp; write access is enabled on the <code>upload/</code> directory as without it, our PHP scripts will not be able to read or write to the datasets directory or the metadata and log files.</p> <p>The following script backs up the <code>datasets/*</code> directory, the <code>metadata.json</code> file, and then clones the repository from GitHub and updates the <code>var/www/html/upload/</code> directory. </p> <pre><code>rm -rf ./KDL_SRIP23\n# Place your own repo here\ngit clone https://github.com/RelativisticMechanic/KDL_SRIP23\n# Save the datasets directory\nsudo cp -R /var/www/html/upload/datasets/* ~/datasets/\n# Save the metadata json\nsudo cp -R /var/www/html/upload/metadata.json ./metadata.json\nsudo cp -R /var/www/html/upload/log.txt ./log.txt\nsudo rm -rf /var/www/html/upload\nsudo mkdir /var/www/html/upload\nsudo cp -r ./KDL_SRIP23/data_ingestion/* /var/www/html/upload/\nsudo cp -R ./datasets/* /var/www/html/upload/datasets/\nsudo cp ./metadata.json /var/www/html/upload\nsudo cp ./log.txt /var/www/html/upload/\nsudo chmod -R 777 /var/www/html/upload/\n</code></pre> <p>Save it as something like <code>update_website.sh</code> in the user home directory (usually <code>/home/iiitb/</code>) and remember to <code>chmod +x ./update_website.sh</code>.</p>"},{"location":"setup-server/#enabling-php-limits","title":"Enabling PHP Limits","text":"<p>By default Apache2 is configured to only around a POST data of 8 MB and file data of 2 MB. This is obviously not ideal for us as some of the CSV files can be as large as 70-80 MB. So we'll have to change this.</p> <p>Open up the php.ini for Apache2 in the editor of your choice,</p> <pre><code>sudo vim /etc/php/8.1/apache2/php.ini\n</code></pre> <p>Now find and set the following variables.</p> <pre><code>post_max_size=128M\nupload_max_filesize=100M\n</code></pre> <p>Now, restart Apache.</p> <pre><code>sudo service apache2 restart\n</code></pre>"},{"location":"setup-server/#setting-up-python-on-the-server","title":"Setting up Python on the Server","text":"<p>This bothered me a lot as it seems that pip does not install packages system wide. So even if pandas was installed for the user <code>iiitb</code>, the Python scripts being executed by the PHP script called by Apache2 were not able find pandas. </p> <p>The workaround was to simply install pip packages with root (<code>sudo pip install ...</code>) but that is a very hacky solution and I haven't yet figured out how to set up a Python virtual environment for Apache2.</p>"},{"location":"setup-server/#setting-up-druid-as-service","title":"Setting up Druid as Service","text":"<p>Unlike in a development environment when you'll have Druid running in one of your terminals, this is not possible on a server environment where Druid needs to be running in the background as a service. So we'll need to set Druid up as a service.</p> <p>Once you've downloaded and extracted Druid to the directory <code>/home/iiitb/Druid/</code>, open the file <code>/etc/systemd/system/druid.service</code> in your text editor and place the following configuration:</p> <pre><code>[Unit]\nDescription=Apache Druid Daemon\nDocumentation=http://druid.io\nRequires=network.target\nAfter=network.target\n[Service]\nType=simple\nWorkingDirectory=/home/iiitb/Druid/apache-druid-26.0.0\nUser=iiitb\nGroup=iiitb\nExecStart=/home/iiitb/Druid/apache-druid-26.0.0/bin/start-druid\n[Install]\nWantedBy=default.target\n</code></pre> <p>This sets up Druid as a service. Now, we need to update systemd of our changes. Simply run:</p> <p><code>sudo systemctl daemon-reload</code></p> <p>No errors should be reported. Now, start Druid by:</p> <p><code>sudo systemctl start druid</code></p> <p>Congratulations, you have set up the server environment.</p>"},{"location":"tech-stack/","title":"Tech Stack","text":"<p>Currently, all the utilities are running on the WSL-CADS server. The server itself uses Apache2 and runs a copy of Ubuntu 22.04 LTS at the time of writing this documentation.</p>"},{"location":"tech-stack/#frontend","title":"Frontend","text":"<p>The frontend code is written entirely in HTML, CSS and Javascript. It uses Bootstrap 5.0.1 for the UI and Font-Awesome 6.4.0 for various UI icons. The retrieval page uses FileSaver.js and ACE 1.5.0 Editor for saving CSVs on the client machine and allowing SQL code to be written in a nicely presentable manner.</p>"},{"location":"tech-stack/#backend","title":"Backend","text":"<p>The backend is written entirely in PHP 8.1. Various utilities are written in Python that are then called through <code>shell_exec</code> in the PHP code.</p>"},{"location":"tech-stack/#data-solution","title":"Data Solution","text":"<p>The data solution used is Apache Druid 26.0.0. It resides on the CADS server and can be either interacted with using the Druid Console on localhost:8888, or if you are unable to, as would be the case if you are working remotely, can be partially observed via the Druid Status page to view task logs and execute SQL queries.</p>"},{"location":"workflow/","title":"Workflow","text":"<pre><code>graph TD\n  A[\"Files with metadata\"] --&gt; B{Upload Form};\n  B --&gt; C{\"CADS Server\"};\n  C --&gt;|\"CSV/XLSX/etc. Files\"| D{\"datasets/\"}\n  C --&gt;|\"Metadata\"| E{\"metadata.json\"}\n  D --&gt;|\"XLSX files\"| F{\"To CSV\"}\n  D --&gt;|\"CSV files\"| G[(\"Druid\")]\n  F --&gt; G\n  G --&gt; H{\"Data Catalog\"}\n  E --&gt; H\n  G --&gt; I{\"Druid Status\"}\n  G --&gt; J{\"Ontology\"}\n  H --&gt; J</code></pre>"},{"location":"source-code/csv-from-druid.php/","title":"CSV-FROM-DRUID.PHP","text":""},{"location":"source-code/csv-from-druid.php/#function","title":"Function","text":"<p>Web interface to <code>csv_from_druid.py</code>.</p>"},{"location":"source-code/csv-from-druid.php/#working","title":"Working","text":"<p>It accepts the query as a POST request with \"query\" as the query and forwards it to <code>csv_from_druid.py</code>. It returns the JSON outputted by <code>csv_from_druid.py</code> to the client.</p>"},{"location":"source-code/csv-from-druid.php/#used-by","title":"Used By","text":"<ul> <li><code>retrieval.php</code></li> </ul>"},{"location":"source-code/csv_from_druid.py/","title":"CSV_FROM_DRUID.PY","text":""},{"location":"source-code/csv_from_druid.py/#function","title":"Function","text":"<p>Returns CSV data from Druid given query as argument.</p>"},{"location":"source-code/csv_from_druid.py/#working","title":"Working","text":"<p>It accepts the query as an argument and calls <code>ExecuteSQLQueryGetCSV()</code> <code>from pydruid_helper.py</code>.</p> <p>If the query suceeded, the program prints:</p> <p><code>{ \"Error\": \"\", \"CSV\": \"...\" }</code></p> <p>If it fails, the program prints:</p> <p><code>[{ \"Error\": \"Error Message\", \"Message\": \"Full Message from Druid\" }]</code></p>"},{"location":"source-code/csv_from_druid.py/#used-by","title":"Used By","text":"<ul> <li><code>csv-from-druid.php</code></li> </ul>"},{"location":"source-code/data-catalog.php/","title":"DATA-CATALOG.PHP","text":""},{"location":"source-code/data-catalog.php/#function","title":"Function","text":"<p>This is the data catalog that queries the local Druid cluster and then outputs an interactive HTML page.</p>"},{"location":"source-code/data-catalog.php/#working","title":"Working","text":"<p>First the PHP script calls <code>/usr/bin/python3 fetch_catalog.py</code> through PHP's <code>shell_exec</code> which stores the catalog into a local file called <code>dataset-catalog.csv</code>.</p> <p>This <code>dataset-catalog.csv</code> is then read and turned into an HTML table by the PHP and send to the client.</p> <p>In addition, the catalog adds an <code>onClick</code> handler to the dataset filenames that cause an AJAX request to <code>fetch.php</code> that returns an HTML table containing the first 100 rows from Druid, which is then appended to a modal that is presented to the user.</p>"},{"location":"source-code/druid-query.php/","title":"DRUID-QUERY.PHP","text":""},{"location":"source-code/druid-query.php/#function","title":"Function","text":"<p>This PHP file takes a JSON POST and forwards it to the Druid instance, then it returns a sanitized JSON array which contains the table returned by Druid.</p>"},{"location":"source-code/druid-query.php/#working","title":"Working","text":"<p>It calls <code>query_exec.py</code> with the query received as an argument. </p>"},{"location":"source-code/druid-query.php/#used-by","title":"Used By","text":"<ul> <li><code>druid-status.php</code>'s Druid monitor uses this to allow remote queries to the Druid instance for debugging purposes.</li> </ul>"},{"location":"source-code/druid-status.php/","title":"DRUID_STATUS.PHP","text":""},{"location":"source-code/druid-status.php/#function","title":"Function","text":"<p>The Druid status page. Used for debugging the cluster. It shows server information, Druid task log, output of <code>log.txt</code>, and allows the programmer to execute custom queries to the Druid cluster from the web interface.</p>"},{"location":"source-code/druid-status.php/#working","title":"Working","text":"<p>The Druid task log is retrieved by calling <code>get_tasks.py</code> through <code>shell_exec</code> and is turned into a table. The <code>log.txt</code> is read using PHP's <code>fread()</code> and the server information is read using PHP's <code>file_get_contents()</code> to the local Druid instance on localhost:8888/status.</p> <p>The Druid monitor works by sending user typed queries to <code>druid-query.php</code> as an AJAX request and then outputs them into a table format in a <code>&lt;div&gt;</code> located below the input.</p>"},{"location":"source-code/druid_lib.py/","title":"DRUID_LIB.PY","text":""},{"location":"source-code/druid_lib.py/#function","title":"Function","text":"<p>It contains the two major functions <code>get_druid_json()</code> and <code>ingest_to_druid()</code> which are used by the ingestion pipeline to forward CSVs to the Druid cluster.</p>"},{"location":"source-code/druid_lib.py/#working","title":"Working","text":"<p>The original file was contributed by Phani on the WSL-CADS-CODR repository in 2021 as <code>ingest.py</code>. I only modified parts of the code and made it usable in a general purpose scenario.</p> <p><code>get_druid_json(file_name, file_path, json_file_name)</code> creates a JSON spec that is required to be send to the Druid API with a POST request. It takes in a CSV file name, directory of the CSV, and the JSON file name to be created. It creates the JSON containing the required Druid spec (mostly the data types of every column, and a few other things). It then returns the JSON object.</p> <p><code>ingest_to_druid(json_object)</code> sends that POST request to the Druid cluster.</p>"},{"location":"source-code/druid_lib.py/#used-by","title":"Used By","text":"<ul> <li>upload_batch_druid.py</li> <li>upload_single_druid.py</li> </ul>"},{"location":"source-code/fetch.php/","title":"FETCH.PHP","text":""},{"location":"source-code/fetch.php/#function","title":"Function","text":"<p>Returns an HTML table containing the first 100 rows of a dataset name given by \"datasetName\" as part of a GET query.</p>"},{"location":"source-code/fetch.php/#working","title":"Working","text":"<p>It calls a Python script <code>fetch_rows.py</code> using PHP's <code>shell_exec</code> with the <code>datasetName</code> as an argument. The output of <code>fetch_rows.py</code> is then turned into an HTML table and returned to the client.</p>"},{"location":"source-code/fetch.php/#usage","title":"Usage","text":"<ul> <li><code>data-catalog.php</code> does an AJAX call to <code>fetch.php</code> from the client side to fetch 100 rows. The <code>fetch_url</code> passed to <code>fetch100Rows(fetch_url)</code> is <code>fetch.php?datasetName=&lt;dataset selected by user&gt;</code>. <code>fetch100Rows()</code> does an AJAX call and then outputs the 100 rows to a Bootstrap modal which is then shown to user.</li> </ul>"},{"location":"source-code/fetch_catalog.py/","title":"FETCH_CATALOG.PY","text":""},{"location":"source-code/fetch_catalog.py/#function","title":"Function","text":"<p>It fetches the data catalog along with the metadata from the Druid cluster and <code>metadata.json</code> into a CSV file <code>dataset-catalog.csv</code> which is then read by <code>data-catalog.php</code>.</p>"},{"location":"source-code/fetch_catalog.py/#working","title":"Working","text":"<p>First it sends the query <code>SELECT * FROM \"INFORMATION_SCHEMA\".\"TABLES\" WHERE \"TABLE_SCHEMA\" = 'druid'</code> to the cluster, this returns all the sets of tables loaded into the cluster. Then, it iterates through each to find whether the column <code>KDL_METADATA</code> exists as the metadata writer writes the first row into this column as a JSON object containing the metadata, if it does not, then it looks for a JSON entry in the local <code>metadata.json</code>. It then adds this row to the pandas DataFrame which is finally outputted as <code>dataset-catalog.csv</code>.</p> <p>Warning</p> <p>It seems that KDL_METADATA row is almost always discarded by Druid. So, it is advisable to keep the <code>metadata.json</code> intact, and it will likely be the only copy of the metadata for the tables.</p>"},{"location":"source-code/fetch_catalog.py/#used-by","title":"Used By","text":"<ul> <li><code>data-catalog.php</code></li> </ul>"},{"location":"source-code/fetch_rows.py/","title":"FETCH_ROWS.PY","text":""},{"location":"source-code/fetch_rows.py/#function","title":"Function","text":"<p>This is a Python script that fetches the first 100 rows. </p>"},{"location":"source-code/fetch_rows.py/#working","title":"Working","text":"<p>It sends a <code>SELECT * from sys.argv[1]</code> query to the local Druid instance using <code>pydruid_helper.py</code>. Then outputs a dataframe ordered by records turned into a JSON string that is read by PHP as return value of <code>shell_exec()</code>.</p>"},{"location":"source-code/fetch_rows.py/#used-by","title":"Used By","text":"<ul> <li><code>fetch.php</code> uses this script and turns the output into an HTML table which is sent to the client.</li> </ul>"},{"location":"source-code/form-upload.php/","title":"FORM-UPLOAD.PHP","text":""},{"location":"source-code/form-upload.php/#function","title":"Function","text":"<p>This is the page that contains the form to upload a file or a batch of files to the Druid cluster. Although the name is misleading as it is largely HTML with no PHP code in it. </p> <p>The form sends a POST request to either <code>upload.php</code> or <code>upload-batch.php</code> depending upon whether the user chooses to upload a single file or multiple files.</p>"},{"location":"source-code/get_tasks.py/","title":"GET_TASKS.PY","text":""},{"location":"source-code/get_tasks.py/#function","title":"Function","text":"<p>Gets the Druid task log. Used by <code>druid-status.php</code> to generate a human readable HTML table of previous executed Druid tasks. </p> <p>Note</p> <p>Druid's console provides the same functionality, but it is inaccessible remotely.</p>"},{"location":"source-code/get_tasks.py/#used-by","title":"Used By","text":"<ul> <li><code>druid-status.php</code></li> </ul>"},{"location":"source-code/helper.php/","title":"HELPER.PHP","text":""},{"location":"source-code/helper.php/#function","title":"Function","text":"<p>It contains some common helpful routines.</p>"},{"location":"source-code/helper.php/#working","title":"Working","text":"<p>It contains functions like <code>error(msg)</code> and <code>notify(msg)</code> which automatically create a nice looking Bootstrap alert. It also contains <code>get_SDG_flags()</code> which turns the SDG checkboxes received into a bitwise represenation which can be stored simply as an integer. </p>"},{"location":"source-code/helper.php/#used-by","title":"Used By","text":"<ul> <li><code>upload.php</code></li> <li><code>upload-batch.php</code></li> </ul>"},{"location":"source-code/index.php/","title":"INDEX.PHP","text":""},{"location":"source-code/index.php/#function","title":"Function","text":"<p>This is the page shown when the user visits http://cads.iiitb.ac.in/upload/ page, it is meant to serve as a landing page.</p>"},{"location":"source-code/js_ace1.5.0/","title":"JS/ACE-1.5.0","text":""},{"location":"source-code/js_ace1.5.0/#function","title":"Function","text":"<p>Contains the files for ACE Editor 1.5.0, that is used by the SQL Editor in the retrieval page.</p>"},{"location":"source-code/js_ace1.5.0/#used-by","title":"Used By","text":"<ul> <li><code>retrieval.php</code></li> </ul>"},{"location":"source-code/js_druid-query.js/","title":"JS/DRUID-QUERY.JS","text":""},{"location":"source-code/js_druid-query.js/#function","title":"Function","text":"<p>Used by <code>druid-status.php</code> to allow the client to send AJAX requests to <code>druid-query.php</code> which is used by the Druid monitor.</p>"},{"location":"source-code/js_druid-query.js/#working","title":"Working","text":"<p>It provides a <code>sendQueryToPHP()</code> which sends the Druid SQL query in a textbox with id \"druid_query\" to <code>druid-query.php</code> as a POST request in a JSON file. On success, it calls another function provided by it called <code>buildTable()</code> which generates an HTML table from the query. Error handling is done on the server side, so in case of an error, an error table containing an error message is returned by <code>query_exec.py</code> which is forwarded to <code>druid-query.php</code> which then forwards it to there.</p>"},{"location":"source-code/js_druid-query.js/#used-by","title":"Used By","text":"<ul> <li><code>druid-status.php</code></li> </ul>"},{"location":"source-code/js_generate-checkboxes.js/","title":"JS/GENERATE-CHECKBOXES.JS","text":""},{"location":"source-code/js_generate-checkboxes.js/#function","title":"Function","text":"<p>A helper routine in JavaScript to generate the 17 SDG checkboxes in the form upload.</p>"},{"location":"source-code/js_generate-checkboxes.js/#used-by","title":"Used By","text":"<ul> <li><code>form-upload.php</code></li> </ul>"},{"location":"source-code/js_query-table-builder.js/","title":"JS/QUERY-TABLE-BUILDER.JS","text":""},{"location":"source-code/js_query-table-builder.js/#function","title":"Function","text":"<p>It contains the function <code>buildTableFromQuery(json_data, selector, maxLimit)</code> which builds an HTML table from the given JSON data, puts it into the selector. maxLimit is the number of maximum rows to append to the selector.</p>"},{"location":"source-code/js_query-table-builder.js/#used-by","title":"Used By","text":"<ul> <li><code>retrival.php</code></li> <li><code>druid-status.php</code></li> </ul>"},{"location":"source-code/js_retrieval.js/","title":"JS/RETRIEVAL.JS","text":""},{"location":"source-code/js_retrieval.js/#function","title":"Function","text":"<p>Javascript code for the retrieval.php page.</p>"},{"location":"source-code/js_upload-batch.js/","title":"JS/UPLOAD-BATCH.JS","text":""},{"location":"source-code/js_upload-batch.js/#function","title":"Function","text":"<p>A helper routine in JavaScript that creates the controls to add multiple files using Bootstrap.</p>"},{"location":"source-code/js_upload-batch.js/#used-by","title":"Used By","text":"<ul> <li><code>form-upload.php</code></li> </ul>"},{"location":"source-code/logger.py/","title":"LOGGER.PY","text":""},{"location":"source-code/logger.py/#function","title":"Function","text":"<p>This Python script contains two functions <code>Log()</code> and <code>LogException()</code>. Both output a string with the timestamp attached to <code>log.txt</code>, except the <code>LogException()</code> adds a <code>*** EXCEPTION ***</code>.</p> <p>It is recommended that if you are adding an Python code, to use this logger. When your code is deployed on the server, there is no stdout, or stderr, thus having the <code>log.txt</code> file to see what went wrong at some point helps.</p>"},{"location":"source-code/logger.py/#usage","title":"Usage","text":"<ul> <li> <p>Almost every Python script logs it activity into <code>log.txt</code> for debugging purposes. </p> </li> <li> <p><code>druid-status.php</code> reads <code>log.txt</code> and displays it.</p> </li> </ul>"},{"location":"source-code/metadata_writer.py/","title":"METADATA_WRITER.PY","text":""},{"location":"source-code/metadata_writer.py/#function","title":"Function","text":"<p>Writes the metadata into a separate column called <code>KDL_METADATA</code> into a CSV and stores a backup in <code>metadata.json</code>.</p>"},{"location":"source-code/metadata_writer.py/#working","title":"Working","text":"<p>Both <code>upload.php</code> and <code>upload-batch.php</code> write a temporary file called <code>tmp.meta</code> which contains the metadata (Name, Year, SDG Checkbox Data, etc.) entered by the user. This turns it into a Python dict, and attaches it to the CSV being sent by adding a column called <code>KDL_METADATA</code> and adds the entry to the local <code>metadata.json</code> as well. Both are read by <code>fetch_catalog.py</code>.</p> <p>Warning</p> <p>It seems that KDL_METADATA row is almost always discarded by Druid. So, it is advisable to keep the <code>metadata.json</code> intact, and it will likely be the only copy of the metadata for the tables.</p>"},{"location":"source-code/metadata_writer.py/#used-by","title":"Used By","text":"<ul> <li><code>upload_single_druid.py</code></li> <li><code>upload_batch_druid.py</code></li> </ul>"},{"location":"source-code/pydruid_helper.py/","title":"PYDRUID_HELPER.PY","text":""},{"location":"source-code/pydruid_helper.py/#function","title":"Function","text":"<p>It implements <code>ExecuteSQLQuery()</code> (returns a pandas dataFrame) and <code>ExecuteSQLQueryGetJSON()</code> (returns a JSON) which can be used to receive results of queries from Druid SQL.</p> <p>Note</p> <p>The filename was originally <code>pydruid_helper</code> as it used the <code>pydruid</code> library, but I realized for our purposes that Python <code>requests</code> was enough and simple. So I removed the Pydruid code but retained the name.</p>"},{"location":"source-code/pydruid_helper.py/#used-by","title":"Used By","text":"<ul> <li><code>query_exec.py</code></li> <li><code>fetch_catalog.py</code></li> <li><code>fetch_rows.py</code></li> </ul>"},{"location":"source-code/query_exec.py/","title":"QUERY_EXEC.PY","text":""},{"location":"source-code/query_exec.py/#function","title":"Function","text":"<p>Execute a query to the Druid cluster just by passing it as an argument to this script.</p>"},{"location":"source-code/query_exec.py/#working","title":"Working","text":"<p>It simply calls <code>ExecuteSQLQueryGetJSON()</code> from <code>pydruid_helper.py</code> with argument as <code>sys.argv[1]</code>.</p>"},{"location":"source-code/query_exec.py/#used-by","title":"Used By","text":"<ul> <li><code>druid_status.php</code> as part of the Druid monitor</li> </ul>"},{"location":"source-code/retrieval.php/","title":"RETRIEVAL.PHP","text":""},{"location":"source-code/retrieval.php/#function","title":"Function","text":"<p>PHP page to retrieve data from the cluster. Allows grouping of data as per SDGs, and also allows custom queries and viewing available ontologies.</p>"},{"location":"source-code/retrieval.php/#working","title":"Working","text":"<p>It uses <code>csv-from-druid.php</code> which queries Druid for CSV format. It also uses ACE 1.5.0 editor for the SQL editor to make it easy to write SQL code on the browser itself. It uses FileSaver.js to provide file saving functionality.</p>"},{"location":"source-code/settings.py/","title":"SETTINGS.PY","text":""},{"location":"source-code/settings.py/#function","title":"Function","text":"<p>Contains common settings used by all Python scripts, such as Druid server location, datasets directory and other global settings.</p>"},{"location":"source-code/settings.py/#used-by","title":"Used By","text":"<ul> <li>All *.py scripts</li> </ul>"},{"location":"source-code/styles_tables.css/","title":"TABLES.CSS.MD","text":""},{"location":"source-code/styles_tables.css/#function","title":"Function","text":"<p>Contains cascading style sheets for tables. It looks good.</p>"},{"location":"source-code/styles_tables.css/#used-by","title":"Used By","text":"<ul> <li><code>data-catalog.php</code></li> <li><code>druid-status.php</code></li> </ul>"},{"location":"source-code/upload-batch.php/","title":"UPLOAD-BATCH.PHP","text":""},{"location":"source-code/upload-batch.php/#function","title":"Function","text":"<p>This is the first part of the ingestion mechanism. After the files and metadata from the user is received from the <code>form-upload.php</code>, for batch file upload (CSV/XLSX) this file is invoked.</p>"},{"location":"source-code/upload-batch.php/#working","title":"Working","text":"<p>The first thing that it does is validate the data, whether SDGs have been checked, name, year, and other details have been provided. </p> <p>Next, it creates something called \"SDG Flags\" (<code>sdg_flags</code>). As there are 17 Sustainable Development Goals, the most efficient way to store all SDGs is by creating a number where bits 1-17 will specify whether the relevant SDG applies to the data set or not. This \"SDG Flag\" is used by all utilities.</p> <p>Then it uses PHP's <code>move_uploaded_file()</code> to move all files uploaded from the temporary POST storage to the <code>datasets/&lt;Data Set Name&gt;/</code> directory. It also adds a UNIX timestamp in front of the directory to preserve its uniqueness. For every file uploaded, it adds a <code>$count</code> to preserve its uniqueness again, in case the user uploaded two files with identical names. As an example, if the user uploaded files as FILE1.CSV, and FILE2.XLSX, and gave the dataset name as \"My Data Set\", the files on the server would go in: datasets/16492329323_My Data Set/FILE1.CSV and datasets/16492329323_My Data Set/FILE2.XLSX.</p> <p>Next, it creates a file called <code>tmp.meta</code>, which contains all the metadata (SDG Flags, Year, Name, Description, etc.) that will be read by <code>metadata_writer.py</code>.</p> <p>Finally, it calls <code>upload_batch_druid.py</code> with the given directory name.</p>"},{"location":"source-code/upload.php/","title":"UPLOAD.PHP","text":""},{"location":"source-code/upload.php/#function","title":"Function","text":"<p>This is the first part of the ingestion mechanism. After the files and metadata from the user is received from the <code>form-upload.php</code>, for a single file upload (CSV/XLSX) this file is invoked.</p>"},{"location":"source-code/upload.php/#working","title":"Working","text":"<p>The first thing that it does is validate the data, whether SDGs have been checked, name, year, and other details have been provided. </p> <p>Next, it creates something called \"SDG Flags\" (<code>sdg_flags</code>). As there are 17 Sustainable Development Goals, the most efficient way to store all SDGs is by creating a number where bits 1-17 will specify whether the relevant SDG applies to the data set or not. This \"SDG Flag\" is used by all utilities.</p> <p>Then it checks for the file size (50 MB limit imposed), and uses PHP's <code>move_uploaded_file()</code> to move it from the temporary POST storage to the <code>datasets/</code> directory. It also adds a UNIX timestamp in front of the filename to preserve its uniqueness. Next, it creates a file called <code>tmp.meta</code>, which contains all the metadata (SDG Flags, Year, Name, Description, etc.) that will be read by <code>metadata_writer.py</code>.</p> <p>Finally, it calls <code>upload_single_druid.py</code> with the given filename.</p>"},{"location":"source-code/upload_batch_druid.py/","title":"UPLOAD_SINGLE_DRUID.PY","text":""},{"location":"source-code/upload_batch_druid.py/#function","title":"Function","text":"<p>Sends a single XLSX/CSV file to Druid instance.</p>"},{"location":"source-code/upload_batch_druid.py/#working","title":"Working","text":"<p>It takes in the argument as a directory, and iterates over the items in that directory.</p> <ul> <li> <p>If it is a CSV file, then it uses <code>druid_lib.py</code>'s functions to create a JSON spec, then calls <code>WriteMetaData()</code> to write it, and sends it to Druid using <code>ingest_to_druid()</code>.</p> </li> <li> <p>If it is an XLSX file, then it uses <code>xlsx2csv.py</code>'s <code>convert2CSV()</code> which returns an array of CSV file names corresponding to every Excel sheet, and then calls <code>WriteMetaData()</code> every time a CSV is sent to Druid.</p> </li> <li> <p>All other files are ignored.</p> </li> </ul>"},{"location":"source-code/upload_batch_druid.py/#used-by","title":"Used By","text":"<ul> <li><code>upload-batch.php</code></li> </ul>"},{"location":"source-code/upload_single_druid.py/","title":"UPLOAD_SINGLE_DRUID.PY","text":""},{"location":"source-code/upload_single_druid.py/#function","title":"Function","text":"<p>Sends a single XLSX/CSV file to Druid instance.</p>"},{"location":"source-code/upload_single_druid.py/#working","title":"Working","text":"<p>If it is a CSV file, then it uses <code>druid_lib.py</code>'s functions to create a JSON spec, then calls <code>WriteMetaData()</code> to write it, and sends it to Druid using <code>ingest_to_druid()</code>.</p> <p>If it is an XLSX file, then it uses <code>xlsx2csv.py</code>'s <code>convert2CSV()</code> which returns an array of CSV file names corresponding to every Excel sheet, and then calls <code>WriteMetaData()</code> every time a CSV is sent to Druid.</p>"},{"location":"source-code/upload_single_druid.py/#used-by","title":"Used By","text":"<ul> <li><code>upload.php</code></li> </ul>"},{"location":"source-code/xlsx2csv.py/","title":"XLSX2CSV.PY","text":""},{"location":"source-code/xlsx2csv.py/#function","title":"Function","text":"<p>If an XLSX file is uploaded, two things need to be done:</p> <ol> <li>Convert the XLSX to CSV.</li> <li>Turn each sheet of the XLSX into a separate CSV to be sent to Druid.</li> </ol>"},{"location":"source-code/xlsx2csv.py/#working","title":"Working","text":"<p>It contains a function called <code>convert2CSV</code> which takess a directory name, and the Excel file name, and then iterates over its sheets turning every sheet into a separate CSV. The sheet names are appended to the filename with an underscore to generate a new CSV file name. It then turns an array containing the names of all CSVs outputted.</p> <p>As an example, if the input is \"FILE.XLSX\" with \"SHEET1\" and \"SHEET2\", <code>convert2CSV</code> will create two files, \"FILE_SHEET1.CSV\" and \"FILE_SHEET2.CSV\", and return the Pythonic array <code>[\"FILE1_SHEET1.CSV\", \"FILE2_SHEET2.CSV\"]</code>.</p>"},{"location":"source-code/xlsx2csv.py/#used-by","title":"Used By","text":"<ul> <li><code>upload_single_druid.py</code></li> <li><code>upload_batch_druid.py</code></li> </ul>"}]}